{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0348a-6f0e-428f-b232-a191d75667cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Image class from the PIL (Pillow) library\n",
    "from PIL import Image\n",
    "\n",
    "# Import the requests library to make HTTP requests\n",
    "import requests\n",
    "\n",
    "# Define the URL of the image you want to download\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "\n",
    "# Use the requests library to download the image and open it with PIL\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Display the image\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2740d-c589-4481-8edd-cb7f044c89a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary classes from the transformers library\n",
    "from transformers import GroundingDinoProcessor, GroundingDinoForObjectDetection\n",
    "\n",
    "# Initialize the processor using a pre-trained model checkpoint\n",
    "processor = GroundingDinoProcessor.from_pretrained(\"IDEA-Research/grounding-dino-base\")\n",
    "\n",
    "# Initialize the object detection model using the same pre-trained model checkpoint\n",
    "model = GroundingDinoForObjectDetection.from_pretrained(\"IDEA-Research/grounding-dino-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d96a5-235a-4e5b-a8d7-90b2c4b16433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text caption\n",
    "text = \"a cat\"\n",
    "\n",
    "# Define a function to preprocess the caption text\n",
    "def preprocess_caption(caption: str) -> str:\n",
    "    # Convert the caption to lowercase and remove leading/trailing whitespace\n",
    "    result = caption.lower().strip()\n",
    "    # Check if the caption ends with a period\n",
    "    if result.endswith(\".\"):\n",
    "        return result\n",
    "    # If not, append a period to the caption\n",
    "    return result + \".\"\n",
    "\n",
    "# Preprocess the caption text\n",
    "processed_text = preprocess_caption(text)\n",
    "\n",
    "# Use the processor to prepare the inputs for the model\n",
    "inputs = processor(images=image, text=processed_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7bced-eedc-4806-9d18-2b1872b7922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the torch library\n",
    "import torch\n",
    "\n",
    "# Perform inference without computing gradients (to save memory and computation)\n",
    "with torch.no_grad():\n",
    "    # Get the outputs from the model by passing the processed inputs\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a62610-2fcb-48a3-bb8f-f8427c543d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the matplotlib library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define colors for bounding box visualization\n",
    "COLORS = [\n",
    "    [0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "    [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]\n",
    "]\n",
    "\n",
    "# Define a function to plot the results\n",
    "def plot_results(pil_img, scores, labels, boxes):\n",
    "    # Set the size of the plot\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(pil_img)\n",
    "    \n",
    "    # Get the current axis\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Repeat the colors to ensure there are enough for all boxes\n",
    "    colors = COLORS * 100\n",
    "    \n",
    "    # Iterate over the scores, labels, boxes, and colors\n",
    "    for score, label, (xmin, ymin, xmax, ymax), c in zip(scores, labels, boxes, colors):\n",
    "        # Add a rectangle for each bounding box\n",
    "        ax.add_patch(plt.Rectangle(\n",
    "            (xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "            fill=False, color=c, linewidth=3\n",
    "        ))\n",
    "        \n",
    "        # Create a label with the text and score\n",
    "        label = f'{label}: {score:0.2f}'\n",
    "        \n",
    "        # Add the label to the plot\n",
    "        ax.text(xmin, ymin, label, fontsize=15,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    # Remove the axis\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab467f4-5017-4c52-a4b2-255b0c0182a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimensions of the image\n",
    "width, height = image.size\n",
    "\n",
    "# Post-process the model outputs to get the final object detection results\n",
    "postprocessed_outputs = processor.image_processor.post_process_object_detection(\n",
    "    outputs,                     # The raw outputs from the model\n",
    "    target_sizes=[(height, width)],  # The target size of the image as a tuple (height, width)\n",
    "    threshold=0.3                # Confidence threshold for filtering detections\n",
    ")\n",
    "\n",
    "# Extract the results for the first image (since we're working with a single image)\n",
    "results = postprocessed_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322935-6374-4aec-8eca-8d41ca457acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the plot_results function to visualize the detection results\n",
    "plot_results(\n",
    "    image,                      # The original image\n",
    "    results['scores'].tolist(), # List of detection scores\n",
    "    results['labels'].tolist(), # List of detected labels\n",
    "    results['boxes'].tolist()   # List of bounding boxes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b3ff3-f1a1-4c3d-835b-ba25e8a271a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the pipeline function from the transformers library\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize a zero-shot object detection pipeline using the specified model and device\n",
    "pipe = pipeline(task=\"zero-shot-object-detection\", model=\"IDEA-Research/grounding-dino-base\", device='cuda:0')\n",
    "\n",
    "# Define the URL of the image to be processed\n",
    "image_url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "\n",
    "# Define the candidate labels (preprocess the text)\n",
    "candidate_labels = [preprocess_caption(text)]\n",
    "\n",
    "# Use the pipeline to perform zero-shot object detection on the image\n",
    "results = pipe(image_url, candidate_labels=candidate_labels, threshold=0.3)\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00bbac7-858b-4003-bf94-810425650495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store scores, labels, and boxes\n",
    "scores, labels, boxes = [], [], []\n",
    "\n",
    "# Iterate over the detection results\n",
    "for result in results:\n",
    "    # Append the score to the scores list\n",
    "    scores.append(result[\"score\"])\n",
    "    \n",
    "    # Append the label to the labels list\n",
    "    labels.append(result[\"label\"])\n",
    "    \n",
    "    # Append the bounding box coordinates as a tuple to the boxes list\n",
    "    boxes.append(tuple(result[\"box\"].values()))\n",
    "\n",
    "# Call the plot_results function to visualize the detection results\n",
    "plot_results(image, scores, labels, boxes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
